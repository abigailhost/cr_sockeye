---
title: "AH_AICc_scbodymass~SP"
author: "Abby Host"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE)
```

#' =====================================================
#' AICc code for Size Corrected Body Mass~SpawningPopulation models
#' =====================================================

### Loading Data
```{r}
rm(list = ls())
library(AICcmodavg)
library(lubridate)
library(ggplot2)

#data loading
bc19 <- read.csv("bodycomp_2019.csv")
bc20 <- read.csv("bodycomp_2020.csv")
bc21 <- read.csv("bodycomp_2021.csv")
#need to bind all together for total body comp dataset, Upper River river only

bc_UR_total <- rbind(bc19[61:172,], bc20[61:120,], bc21[61:182,])
write.csv(bc_UR_total, "upperriver_bodycomp_all.csv")
upperriver_bodycomp_all<-read.csv("upperriver_bodycomp_all.csv")[,-1]
#all data is loaded now

#need to add year to dataset
str(upperriver_bodycomp_all)
upperriver_bodycomp_all$Collection_Date <- as.Date(upperriver_bodycomp_all$Collection_Date)

# Create a new column 'year' from the collection_date
upperriver_bodycomp_all$Year <- year(upperriver_bodycomp_all$Collection_Date)
str(upperriver_bodycomp_all)

#replace blank cell in Sex with NA 
upperriver_bodycomp_all$Sex[upperriver_bodycomp_all$Sex == ""] <- NA
str(upperriver_bodycomp_all)

write.csv(upperriver_bodycomp_all, "upperriver_bodycomp_all.csv")
```

### Import Data for models, check for NAs and eliminate as needed
```{r}
rm(list = ls())
upperriver_bodycomp_PCscores <- "upperriver_bodycomp_PCscores.csv"

# Import the data. Be sure to check the structure of the data and that R is reading continuous and categorical variables appropriately.
DataSet<-read.csv(upperriver_bodycomp_PCscores)[,-1]

### Removing NAs that will mess up levels / model weight
any(is.na(DataSet$Collection_Location)) #FALSE
any(is.na(DataSet$Year)) #FALSE
any(is.na(DataSet$Sex)) #FALSE
any(is.na(DataSet$Collection_RiverMile_m)) # FALSE
any(is.na(DataSet$Elevation_m)) #FALSE


#### CHECK DIRECTION OF PC SCORE ###
library(ggplot2)
ggplot(DataSet, aes(x=Fish_Wt, y=bodysize_pc_g_mm)) +
  geom_point()
#so direction of PC score is positive, can check with other variables


# View DataSet.
head(DataSet)
summary(DataSet)
nrow(DataSet)
str(DataSet)

#Make work metric (migratory difficulty metric where work = F x distance)
DataSet$Elevation_m <- as.numeric(DataSet$Elevation_m)
DataSet$Work <- (DataSet$Collection_RiverMile_m * DataSet$Elevation_m) / (1000*1000) #so work is in km^2 
str(DataSet) 

#convert gonad_wt to grams from kilograms
DataSet$Gonad_Wt_g <- DataSet$Gonad_Wt * 1000

#make response variables factors
DataSet$Collection_Location <- as.factor(DataSet$Collection_Location)
levels(DataSet$Collection_Location) # 7 unique locations
DataSet$Year<- as.factor(DataSet$Year)
levels(DataSet$Year)
DataSet$Sex<- as.factor(DataSet$Sex)
str(DataSet)


#check gonad weight for NAs
any(is.na(DataSet$Gonad_Wt_g))
DataSet[is.na(DataSet$Gonad_Wt_g), ] #need to eliminate these rows or model selection will not work
DataSet <- DataSet[-c(8, 19, 20, 31, 35, 37, 50, 59, 70, 71, 73, 81, 84, 111, 112, 114),]
any(is.na(DataSet$Gonad_Wt_g)) #FALSE

```

### Calculating Size-Corrected Body Mass in DataSet 
```{r}
### Size corrected body mass should be the residuals of linear regression between weight ~ fish body size PC Score ###
# DataSet$bodysize_pc_g_mm = in the correct units already
DataSet$Fish_Wt_g <- DataSet$Fish_Wt*1000 #grams conversion
sizecorrected_bodymass_lm <- lm(DataSet$Fish_Wt_g ~ DataSet$bodysize_pc_g_mm) #linear regression for size corrected body mass
sizecorrected_bodymass_residuals <- residuals(sizecorrected_bodymass_lm) #residuals for regression
plot(sizecorrected_bodymass_residuals, DataSet$bodysize_pc_g_mm)
sizecorrected_bodymass <- as.data.frame(sizecorrected_bodymass_residuals)
DataSet <- cbind(DataSet, sizecorrected_bodymass) #adds the residuals to data set as a variable
str(DataSet)

write.csv(DataSet, "upperriver_bodycomp_SizeCorrectedBodyMass.csv") #should all be according to grams and mm values
```

### Reload data for model sets now that size corrected body mass has been calculated
```{r}
rm(list = ls())
upperriver_bodycomp_all<- "upperriver_bodycomp_SizeCorrectedBodyMass.csv"

# Import the data. Be sure to check the structure of the data and that R is reading continuous and categorical variables appropriately.
DataSet<-read.csv(upperriver_bodycomp_all)[,-1]

### Removing NAs that will mess up levels / model weight
any(is.na(DataSet$Collection_RiverMile_m))
any(is.na(DataSet$Year))
any(is.na(DataSet$Sex))
any(is.na(DataSet$Gonad_Wt_g))

#make response variables factors
DataSet$Collection_Location <- as.factor(DataSet$Collection_Location)
levels(DataSet$Collection_Location) # 7 unique locations
DataSet$Year<- as.factor(DataSet$Year)
levels(DataSet$Year)
DataSet$Sex<- as.factor(DataSet$Sex)
DataSet$Gonad_Wt_g <- as.numeric(DataSet$Gonad_Wt_g)
str(DataSet)


ggplot(DataSet, aes(x = Fish_Wt_g, y = sizecorrected_bodymass_residuals)) + 
  geom_point() #one major outlier

```

### Making Models for sizecorrectedbodymass~SP
```{r}
# Models for reference
scBodyMass_SP_modelset <- "scbodymass_spawningpopulation/SizeCorrectedBodyMass~SpawningPopulation_modelset.csv"

ModelSet<-read.csv(scBodyMass_SP_modelset)

#models
model1 <- lm(sizecorrected_bodymass_residuals~1, data=DataSet)
model2 <- lm(sizecorrected_bodymass_residuals~ Gonad_Wt_g + Work, data = DataSet)
model3 <- lm(sizecorrected_bodymass_residuals~ Gonad_Wt_g + Sex, data = DataSet)
model4 <- lm(sizecorrected_bodymass_residuals~ Gonad_Wt_g + Year, data = DataSet)
model5 <- lm(sizecorrected_bodymass_residuals~ Gonad_Wt_g + Work + Sex, data = DataSet)
model6 <- lm(sizecorrected_bodymass_residuals~ Gonad_Wt_g + Work + Year, data = DataSet)
model7 <- lm(sizecorrected_bodymass_residuals~ Gonad_Wt_g + Sex + Year, data = DataSet)
model8 <- lm(sizecorrected_bodymass_residuals~ Gonad_Wt_g + Work + Sex + Work:Sex, data = DataSet)
model9 <- lm(sizecorrected_bodymass_residuals~ Gonad_Wt_g + Work + Year + Work:Year, data = DataSet)
model10 <- lm(sizecorrected_bodymass_residuals~Gonad_Wt_g + Sex + Year + Sex:Year, data = DataSet)
model11 <- lm(sizecorrected_bodymass_residuals~ Gonad_Wt_g + Work + Sex + Year, data = DataSet)
summary(model6)
```

### AICc Model Selection
```{r}
AIC(model1, model2, model3, model4, model5, model6, model7, model8, model9, model10, model11)

#table of AIC results
mynames1 <- paste("model", as.character(1:11), sep = "")
models <- list(model1, model2, model3, model4, model5, model6, model7, model8, model9, model10, model11)

# Generate AIC table
myaicc1 <- aictab(models, modnames = mynames1)
print(myaicc1)

# Convert AIC table to a data frame for easier manipulation
aic_df <- as.data.frame(myaicc1)
aic_df$ModelName <- c("sizecorrected_bodymass_residuals~ Gonad_Wt_g + Work + Year + Work:Year",
                      "sizecorrected_bodymass_residuals~ Gonad_Wt_g + Work + Year",
                      "sizecorrected_bodymass_residuals~ Gonad_Wt_g + Work + Sex + Year",
                      "sizecorrected_bodymass_residuals~ Gonad_Wt_g + Work",
                      "sizecorrected_bodymass_residuals~ Gonad_Wt_g + Year",
                      "sizecorrected_bodymass_residuals~ Gonad_Wt_g + Work + Sex",
                      "sizecorrected_bodymass_residuals~ Gonad_Wt_g + Sex + Year",
                      "sizecorrected_bodymass_residuals~1",
                      "sizecorrected_bodymass_residuals~ Gonad_Wt_g + Work + Sex + Work:Sex",
                      "sizecorrected_bodymass_residuals~ Gonad_Wt_g + Sex",
                      "sizecorrected_bodymass_residuals~Gonad_Wt_g + Sex + Year + Sex:Year") 
colnames(aic_df)[colnames(aic_df) == "Modnames"] <- "Model #"

# Write the data frame to a CSV file
write.csv(aic_df, file = "scbodymass_spawningpopulation/AICresults_SizeCorrectedBodyMass~SpawningPopulation.csv", row.names = FALSE)

```

### Model Averaging and Parameter Likelihoods
```{r}
# ---- Load necessary packages ----
library(MuMIn)
library(dplyr)

# ---- Step 1: Combine models into a named list ----
models <- list(model1, model2, model3, model4, model5, model6, model7, model8, model9, model10, model11)
model_names <- paste0("Model_", seq_along(models))
names(models) <- model_names

# ---- Step 2: Run model selection (AICc) ----
model_sel <- model.sel(models)

# ---- Step 3: Model averaging (conditional averaging recommended) ----
model_avg <- model.avg(model_sel, full = FALSE)  # full = FALSE for conditional averaging
summary(model_avg)

# ---- Step 4: Extract averaged coefficients and confidence intervals ----
avg_coefs <- coef(model_avg)
avg_confint <- confint(model_avg)
avg_se <- sqrt(diag(vcov(model_avg)))

# ---- Step 5: Create tidy coefficient summary ----
coefs_df <- as.data.frame(avg_coefs)
colnames(coefs_df) <- "Avg_Coef"
coefs_df$CI_Lower <- avg_confint[, 1]
coefs_df$CI_Upper <- avg_confint[, 2]
coefs_df$SE <- avg_se
coefs_df$Parameter <- rownames(coefs_df)

# Reorder for clarity
coefs_df <- coefs_df[, c("Parameter", "Avg_Coef", "SE", "CI_Lower", "CI_Upper")]

# ---- Step 6: Helper function to normalize interaction term names ----
normalize_param_name <- function(name) {
  if (grepl(":", name)) {
    parts <- strsplit(name, ":")[[1]]
    paste(sort(parts), collapse = ":")
  } else {
    name
  }
}

# ---- Step 7: Calculate parameter likelihoods (relative importance) ----
weights <- model_sel$weight

# Extract all unique parameter names across models (normalize interaction terms)
param_names <- unique(unlist(sapply(models, function(m) {
  sapply(names(coef(m)), normalize_param_name)
})))

# Calculate parameter likelihoods safely
param_likelihoods <- sapply(param_names, function(param) {
  models_with_param <- sapply(models, function(m) {
    any(sapply(names(coef(m)), function(p) normalize_param_name(p) == param))
  })
  if (any(models_with_param)) {
    sum(weights[models_with_param])
  } else {
    0  # If not in any model, assign 0
  }
})

# ---- Step 8: Create param_likelihoods_df and merge cleanly ----
param_likelihoods_df <- data.frame(
  Parameter = param_names,
  ParamLikelihood = param_likelihoods
)

# Drop any old ParamLikelihood (if present), then merge cleanly
coefs_df <- coefs_df %>% select(-any_of("ParamLikelihood"))
coefs_df <- left_join(coefs_df, param_likelihoods_df, by = "Parameter")

# ---- Step 9: Sort by parameter likelihood ----
coefs_df <- coefs_df %>%
  arrange(desc(ParamLikelihood))

# ---- Step 9: View or export final result ----
print(coefs_df)
write.csv(coefs_df, "scbodymass_spawningpopulation/scbodymass_spawningpopulation_ModelAvg_Coefs_withLikelihoods.csv", row.names = FALSE)


# ---- Step 10: Table for coefficients and threshold for parameter likelihoods ----
threshold <- 0.1  # Set threshold for importance

# Add a new column to coefs_df that marks important vs non-important parameters
coefs_df$Importance <- ifelse(coefs_df$ParamLikelihood > threshold, "Important", "Non-Important")

# ---- Color Code Important Parameters with Color Blind Friendly Colors ----
# Light green for important, light gray for non-important
library(kableExtra)

# Create the table without adding duplicate headers
coefs_table <- coefs_df %>%
  arrange(desc(ParamLikelihood)) %>%
  kable("html", escape = FALSE, align = c("l", "r", "r", "r", "r", "r", "l")) %>%
  # Apply color coding based on importance
  kable_styling(bootstrap_options = c("striped", "hover")) %>%
  row_spec(which(coefs_df$Importance == "Important"), background = "lightgreen", color = "black") %>%
  row_spec(which(coefs_df$Importance == "Non-Important"), background = "lightgray", color = "black") # Adjust column width if needed

# Print or save the table
coefs_table

```