---
title: "AH_AICc_fecundity~GSI"
author: "Abby Host"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE)
```

#' =====================================================
#' AICc code for Fecundity~GSI models
#' =====================================================

### Loading Data
```{r}
rm(list = ls())
library(AICcmodavg)
library(lubridate)
library(ggplot2)

#data loading, use the bodysize_pc data because it will be a variable of interest
lowerriver_bodycomp_PCscores <- "lowerriver_GSI_PCscores.csv"

# Import the data. Be sure to check the structure of the data and that R is reading continuous and categorical variables appropriately.
DataSet<-read.csv(lowerriver_bodycomp_PCscores)[,-1]
```

### Removing NAs and subsetting female fish for fecundity
```{r}
### Removing NAs that will mess up levels / model weight
any(is.na(DataSet$Collection_Location))
any(is.na(DataSet$Group_Assignment))
any(is.na(DataSet$Year))
any(is.na(DataSet$Sex)) # All false

# View DataSet.
head(DataSet)
summary(DataSet)
nrow(DataSet)
str(DataSet)

#make response variables factors
DataSet$Collection_Location <- as.factor(DataSet$Collection_Location)
DataSet$Group_Assignment <- as.factor(DataSet$Group_Assignment)
levels(DataSet$Group_Assignment) #levels are not all consistent. Need to fix this

# Strip whitespace
DataSet$Group_Assignment <- trimws(DataSet$Group_Assignment)

# Standardize levels
DataSet$Group_Assignment <- factor(DataSet$Group_Assignment)
levels(DataSet$Group_Assignment)


# Clean up levels manually
levels(DataSet$Group_Assignment)[levels(DataSet$Group_Assignment) == "Gulkana "] <- "Gulkana"
levels(DataSet$Group_Assignment)[levels(DataSet$Group_Assignment) == "Gulkanahatchery"] <- "GulkanaHatchery"
levels(DataSet$Group_Assignment)[levels(DataSet$Group_Assignment) == "KlutinaTonsinaOutlets"] <- "KlutinaTonsinaOutlet"
levels(DataSet$Group_Assignment)[levels(DataSet$Group_Assignment) == "insufficient genotypes"] <- "insufficient_genotypes"

# Then drop the insufficient genotypes
DataSet <- subset(DataSet, Group_Assignment != "insufficient_genotypes")
DataSet$Group_Assignment <- droplevels(DataSet$Group_Assignment)

# Confirm new levels
levels(DataSet$Group_Assignment) #should have 10 levels


DataSet$Year<- as.factor(DataSet$Year)
DataSet$Sex<- as.factor(DataSet$Sex)
str(DataSet) #collection_rivermile_m is numeric

DataSetF <- subset(DataSet, Sex == "F")

```

## Calculating Fecundity for the DataSetF 
```{r}
DataSetF$Fecun_num_by_wt1 <- (DataSetF$Fem_Fecun_1_num/DataSetF$Fem_Fecun_1_wt)*(DataSetF$Gonad_Wt * 1000)
#unsure if there is enough of 2 and 3 subsamples to find averages as necessary, so just use the first sub sample here

# View DataSet.
head(DataSetF)
summary(DataSetF)
nrow(DataSetF)
str(DataSetF)

str(DataSetF) #collection_rivermile_m is numeric
```

### Making Models for fecundity~GSI, includes collection location
```{r}
# Models for reference
fecundity_GSI_modelset <- "fecundity_GSI/fecundity~GSI_modelset.csv"

ModelSet<-read.csv(fecundity_GSI_modelset)

model1 <- lm(Fecun_num_by_wt1~1, data=DataSetF)
model2 <- lm(Fecun_num_by_wt1~Collection_RiverMile_m + bodysize_pc, data=DataSetF)
model3 <- lm(Fecun_num_by_wt1~Collection_RiverMile_m + EnergyPDry_1, data=DataSetF)
model4 <- lm(Fecun_num_by_wt1~Collection_RiverMile_m + Group_Assignment, data=DataSetF)
model5 <- lm(Fecun_num_by_wt1~Collection_RiverMile_m + Year, data=DataSetF)
model6 <- lm(Fecun_num_by_wt1~Collection_RiverMile_m + bodysize_pc + EnergyPDry_1, data=DataSetF)
model7 <- lm(Fecun_num_by_wt1~Collection_RiverMile_m + bodysize_pc + Group_Assignment, data=DataSetF)
model8 <- lm(Fecun_num_by_wt1~Collection_RiverMile_m + bodysize_pc + Year, data=DataSetF)
model9 <- lm(Fecun_num_by_wt1~Collection_RiverMile_m + EnergyPDry_1 + Group_Assignment, data=DataSetF)
model10 <- lm(Fecun_num_by_wt1~Collection_RiverMile_m + EnergyPDry_1*Group_Assignment, data=DataSetF)
model11 <- lm(Fecun_num_by_wt1~Collection_RiverMile_m + EnergyPDry_1 + Year, data=DataSetF)
model12 <- lm(Fecun_num_by_wt1~Collection_RiverMile_m + Group_Assignment + Year, data=DataSetF)
model13 <- lm(Fecun_num_by_wt1~Collection_RiverMile_m + bodysize_pc + EnergyPDry_1 + Group_Assignment, data=DataSetF)
model14 <- lm(Fecun_num_by_wt1~Collection_RiverMile_m + bodysize_pc + EnergyPDry_1 + Year, data=DataSetF)
model15 <- lm(Fecun_num_by_wt1~Collection_RiverMile_m + bodysize_pc + Group_Assignment + Year, data=DataSetF)
model16 <- lm(Fecun_num_by_wt1~Collection_RiverMile_m +  EnergyPDry_1 + Group_Assignment + Year, data=DataSetF)
model17 <- lm(Fecun_num_by_wt1~Collection_RiverMile_m + bodysize_pc + EnergyPDry_1 + Group_Assignment + Year, data=DataSetF)

```

### AICc Model Selection
```{r}
AIC(model1, model2, model3, model4, model5, model6, model7, model8, model9, model10, model11, model12, model13, model14, model15, model16, model17)

#table of AIC results
mynames1 <- paste("model", as.character(1:17), sep = "")
models <- list(model1, model2, model3, model4, model5, model6, model7, model8, model9, model10, model11, model12, model13, model14, model15, model16, model17)

# Generate AIC table
myaicc1 <- aictab(models, modnames = mynames1)
print(myaicc1)
# Convert AIC table to a data frame for easier manipulation
aic_df <- as.data.frame(myaicc1)
aic_df$ModelName <- c("Fecun_num_by_wt1~Collection_RiverMile_m + bodysize_pc + Year",
                      "Fecun_num_by_wt1~Collection_RiverMile_m + bodysize_pc",
                      "Fecun_num_by_wt1~1",
                      "Fecun_num_by_wt1~Collection_RiverMile_m + bodysize_pc + EnergyPDry_1 + Year",
                      "Fecun_num_by_wt1~Collection_RiverMile_m + bodysize_pc + EnergyPDry_1",
                      "Fecun_num_by_wt1~Collection_RiverMile_m + bodysize_pc + Group_Assignment",
                      "Fecun_num_by_wt1~Collection_RiverMile_m + Year",
                      "Fecun_num_by_wt1~Collection_RiverMile_m + EnergyPDry_1",
                      "Fecun_num_by_wt1~Collection_RiverMile_m + EnergyPDry_1 + Year",
                      "Fecun_num_by_wt1~Collection_RiverMile_m + Group_Assignment",
                      "Fecun_num_by_wt1~Collection_RiverMile_m + bodysize_pc + EnergyPDry_1 + Group_Assignment",
                      "Fecun_num_by_wt1~Collection_RiverMile_m + bodysize_pc + Group_Assignment + Year",
                      "Fecun_num_by_wt1~Collection_RiverMile_m + EnergyPDry_1 + Group_Assignment",
                      "Fecun_num_by_wt1~Collection_RiverMile_m + Group_Assignment + Year",
                      "Fecun_num_by_wt1~Collection_RiverMile_m + bodysize_pc + EnergyPDry_1 + Group_Assignment + Year",
                      "Fecun_num_by_wt1~Collection_RiverMile_m +  EnergyPDry_1 + Group_Assignment + Year",
                      "Fecun_num_by_wt1~Collection_RiverMile_m + EnergyPDry_1*Group_Assignment")


colnames(aic_df)[colnames(aic_df) == "Modnames"] <- "Model #"

# Write the data frame to a CSV file
write.csv(aic_df, file = "fecundity_GSI/AICresults_Fecundity~GSI.csv", row.names = FALSE)


```

### Model Averaging and Parameter Likelihoods
```{r}
# ---- Load necessary packages ----
library(MuMIn)
library(dplyr)

# ---- Step 1: Combine models into a named list ----
models <- list(model1, model2, model3, model4, model5, model6, model7, model8, model9, model10)
model_names <- paste0("Model_", seq_along(models))
names(models) <- model_names

# ---- Step 2: Run model selection (AICc) ----
model_sel <- model.sel(models)

# ---- Step 3: Model averaging (conditional averaging recommended) ----
model_avg <- model.avg(model_sel, full = FALSE)  # full = FALSE for conditional averaging
summary(model_avg)

# ---- Step 4: Extract averaged coefficients and confidence intervals ----
avg_coefs <- coef(model_avg)
avg_confint <- confint(model_avg)
avg_se <- sqrt(diag(vcov(model_avg)))

# ---- Step 5: Create tidy coefficient summary ----
coefs_df <- as.data.frame(avg_coefs)
colnames(coefs_df) <- "Avg_Coef"
coefs_df$CI_Lower <- avg_confint[, 1]
coefs_df$CI_Upper <- avg_confint[, 2]
coefs_df$SE <- avg_se
coefs_df$Parameter <- rownames(coefs_df)

# Reorder for clarity
coefs_df <- coefs_df[, c("Parameter", "Avg_Coef", "SE", "CI_Lower", "CI_Upper")]

# ---- Step 6: Helper function to normalize interaction term names ----
normalize_param_name <- function(name) {
  if (grepl(":", name)) {
    parts <- strsplit(name, ":")[[1]]
    paste(sort(parts), collapse = ":")
  } else {
    name
  }
}

# ---- Step 7: Calculate parameter likelihoods (relative importance) ----
weights <- model_sel$weight

# Extract all unique parameter names across models (normalize interaction terms)
param_names <- unique(unlist(sapply(models, function(m) {
  sapply(names(coef(m)), normalize_param_name)
})))

# Calculate parameter likelihoods safely
param_likelihoods <- sapply(param_names, function(param) {
  models_with_param <- sapply(models, function(m) {
    any(sapply(names(coef(m)), function(p) normalize_param_name(p) == param))
  })
  if (any(models_with_param)) {
    sum(weights[models_with_param])
  } else {
    0  # If not in any model, assign 0
  }
})

# ---- Step 8: Create param_likelihoods_df and merge cleanly ----
param_likelihoods_df <- data.frame(
  Parameter = param_names,
  ParamLikelihood = param_likelihoods
)

# Drop any old ParamLikelihood (if present), then merge cleanly
coefs_df <- coefs_df %>% select(-any_of("ParamLikelihood"))
coefs_df <- left_join(coefs_df, param_likelihoods_df, by = "Parameter")

# ---- Step 9: Sort by parameter likelihood ----
coefs_df <- coefs_df %>%
  arrange(desc(ParamLikelihood))

# ---- Step 9: View or export final result ----
print(coefs_df)
write.csv(coefs_df, "fecundity_GSI/Fecundity_GSI_ModelAvg_Coefs_withLikelihoods.csv", row.names = FALSE)


# ---- Step 10: Table for coefficients and threshold for parameter likelihoods ----
threshold <- 0.1  # Set threshold for importance

# Add a new column to coefs_df that marks important vs non-important parameters
coefs_df$Importance <- ifelse(coefs_df$ParamLikelihood > threshold, "Important", "Non-Important")

# ---- Color Code Important Parameters with Color Blind Friendly Colors ----
# Light green for important, light gray for non-important
library(kableExtra)

# Create the table without adding duplicate headers
coefs_table <- coefs_df %>%
  arrange(desc(ParamLikelihood)) %>%
  kable("html", escape = FALSE, align = c("l", "r", "r", "r", "r", "r", "l")) %>%
  # Apply color coding based on importance
  kable_styling(bootstrap_options = c("striped", "hover")) %>%
  row_spec(which(coefs_df$Importance == "Important"), background = "lightgreen", color = "black") %>%
  row_spec(which(coefs_df$Importance == "Non-Important"), background = "lightgray", color = "black") # Adjust column width if needed

# Print or save the table
coefs_table

```