---
title: "BodyCompManu_WorkFigures"
author: "Abby Host"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### GSI Early Migratory Work vs condition Figures
```{r, include = FALSE}
library(dplyr)
library(ggplot2)

rm(list = ls())

#Download Work Data set
WorkData <- read.csv("lowerriver_GSI_PCscores.csv")[-1]
str(WorkData)
WorkData$Group_Assignment <- as.factor(WorkData$Group_Assignment)
levels(WorkData$Group_Assignment) #levels are not all consistent. Need to fix this

# Strip whitespace
WorkData$Group_Assignment <- trimws(WorkData$Group_Assignment)

# Standardize levels
WorkData$Group_Assignment <- factor(WorkData$Group_Assignment)
levels(WorkData$Group_Assignment)

# Clean up levels manually
levels(WorkData$Group_Assignment)[levels(WorkData$Group_Assignment) == "Gulkana "] <- "Gulkana"
levels(WorkData$Group_Assignment)[levels(WorkData$Group_Assignment) == "Gulkanahatchery"] <- "GulkanaHatchery"
levels(WorkData$Group_Assignment)[levels(WorkData$Group_Assignment) == "KlutinaTonsinaOutlets"] <- "KlutinaTonsinaOutlet"
levels(WorkData$Group_Assignment)[levels(WorkData$Group_Assignment) == "insufficient genotypes"] <- "insufficient_genotypes"

# Then drop the insufficient genotypes
WorkData <- subset(WorkData, Group_Assignment != "insufficient_genotypes")
WorkData <- subset(WorkData, Group_Assignment != "LowerGroups")
WorkData$Group_Assignment <- droplevels(WorkData$Group_Assignment)



#download coefficient datasets for body size, energy density, total energy
body <- read.csv("bodysize_GSI/bodysize_GSI_ModelAvg_Coefs_withLikelihoods.csv", row.names = 1)
energy_mJkg <- read.csv("energydensity_GSI/EnergyPDry_1_GSI_ModelAvg_Coefs_withLikelihoods.csv", row.names = 1)
energy_mJ <- read.csv("totalenergy_GSI/TotalEnergy_GSI_ModelAvg_Coefs_withLikelihoods.csv", row.names = 1)

#================ body size estimate calculations according to intercept =============
# Step 1: Extract intercept
str(body)
intercept_body <- body["(Intercept)", "Avg_Coef"]

# Step 2: Extract Group_Assignment effects
GSI_body <- body[grep("^Group_Assignment", rownames(body)), ]
GSI_body <- GSI_body[!grepl(":", rownames(GSI_body)), ]  # remove interaction terms

# Extract location names (remove "Collection_Location" from row names)
GSI_body$GSI <- gsub("Group_Assignment", "", rownames(GSI_body))

# Step 3: Add intercept to each to get estimated body size
GSI_body$Estimated_BodySize <- intercept_body + GSI_body$Avg_Coef

# Step 4: Add back the reference location (intercept only)
ref_location <- levels(WorkData$Group_Assignment)[1]  # Assumes first level is the reference
ref_row <- data.frame(
  Avg_Coef = intercept_body,
  CI_Lower = body["(Intercept)", "CI_Lower"],
  CI_Upper = body["(Intercept)", "CI_Upper"],
  SE = body["(Intercept)", "SE"],
  ParamLikelihood = body["(Intercept)", "ParamLikelihood"],
  GSI = ref_location,
  Estimated_BodySize = intercept_body
)

# Step 5: Combine
GSI_body <- rbind(ref_row, GSI_body)
rownames(GSI_body) <- NULL
GSI_body <- GSI_body[, c("GSI", setdiff(names(GSI_body), "GSI"))]

# Step 6: Compute average Work per location
library(dplyr)

# Check unique values
unique(WorkData$Group_Assignment)
avg_work_body <- WorkData %>%
  dplyr::group_by(Group_Assignment) %>%
  dplyr::summarise(Avg_Work = mean(Work_km2, na.rm = TRUE), .groups = "drop")

# Step 7: Merge with estimates
GSI_body <- merge(GSI_body, avg_work_body, by.x = "GSI", by.y = "Group_Assignment") 
str(GSI_body) #final body size dataframe for work regressions





#================ energy density estimate calculations according to intercept =============
# Step 1: Extract intercept
str(energy_mJkg)
intercept_ED <- energy_mJkg["(Intercept)", "Avg_Coef"]

# Step 2: Extract Group_Assignment effects
GSI_ED <- energy_mJkg[grep("^Group_Assignment", rownames(energy_mJkg)), ]
GSI_ED <- GSI_ED[!grepl(":", rownames(GSI_ED)), ]  # remove interaction terms

# Extract location names (remove "Collection_Location" from row names)
GSI_ED$GSI <- gsub("Group_Assignment", "", rownames(GSI_ED))

# Step 3: Add intercept to each to get estimated energy density
GSI_ED$Estimated_EnergyDensity <- intercept_ED + GSI_ED$Avg_Coef

# Step 4: Add back the reference location (intercept only)
ref_location <- levels(WorkData$Group_Assignment)[1]  # Assumes first level is the reference
ref_row2 <- data.frame(
  Avg_Coef = intercept_ED,
  CI_Lower = energy_mJkg["(Intercept)", "CI_Lower"],
  CI_Upper = energy_mJkg["(Intercept)", "CI_Upper"],
  SE = energy_mJkg["(Intercept)", "SE"],
  ParamLikelihood = energy_mJkg["(Intercept)", "ParamLikelihood"],
  GSI = ref_location,
  Estimated_EnergyDensity = intercept_ED
)

# Step 5: Combine
GSI_ED <- rbind(ref_row2, GSI_ED)
rownames(GSI_ED) <- NULL
GSI_ED <- GSI_ED[, c("GSI", setdiff(names(GSI_ED), "GSI"))]

# Step 6: Compute average Work per location
library(dplyr)

# Check unique values
unique(WorkData$Group_Assignment)
avg_work_ED <- WorkData %>%
  dplyr::group_by(Group_Assignment) %>%
  dplyr::summarise(Avg_Work = mean(Work_km2, na.rm = TRUE), .groups = "drop")

# Step 7: Merge with estimates
GSI_ED <- merge(GSI_ED, avg_work_ED, by.x = "GSI", by.y = "Group_Assignment") 
str(GSI_ED) #final energy density dataframe for work regressions



#================ total energy estimate calculations according to intercept =============
# Step 1: Extract intercept
str(energy_mJ)
intercept_TE <- energy_mJ["(Intercept)", "Avg_Coef"]

# Step 2: Extract Group_Assignment effects
GSI_TE <- energy_mJ[grep("^Group_Assignment", rownames(energy_mJ)), ]
GSI_TE <- GSI_TE[!grepl(":", rownames(GSI_TE)), ]  # remove interaction terms

# Extract location names (remove "Collection_Location" from row names)
GSI_TE$GSI <- gsub("Group_Assignment", "", rownames(GSI_TE))

# Step 3: Add intercept to each to get estimated energy density
GSI_TE$Estimated_TotalEnergy <- intercept_TE + GSI_TE$Avg_Coef

# Step 4: Add back the reference location (intercept only)
ref_location <- levels(WorkData$Group_Assignment)[1]  # Assumes first level is the reference
ref_row3 <- data.frame(
  Avg_Coef = intercept_TE,
  CI_Lower = energy_mJ["(Intercept)", "CI_Lower"],
  CI_Upper = energy_mJ["(Intercept)", "CI_Upper"],
  SE = energy_mJ["(Intercept)", "SE"],
  ParamLikelihood = energy_mJ["(Intercept)", "ParamLikelihood"],
  GSI = ref_location,
  Estimated_TotalEnergy = intercept_TE
)

# Step 5: Combine
GSI_TE <- rbind(ref_row3, GSI_TE)
rownames(GSI_TE) <- NULL
GSI_TE <- GSI_TE[, c("GSI", setdiff(names(GSI_TE), "GSI"))]

# Step 6: Compute average Work per location
library(dplyr)

# Check unique values
unique(WorkData$Group_Assignment)
avg_work_TE <- WorkData %>%
  dplyr::group_by(Group_Assignment) %>%
  dplyr::summarise(Avg_Work = mean(Work_km2, na.rm = TRUE), .groups = "drop")

# Step 7: Merge with estimates
GSI_TE <- merge(GSI_TE, avg_work_TE, by.x = "GSI", by.y = "Group_Assignment") 
str(GSI_TE) #final total energy dataframe for work regressions



#================== Now, make figures of regressions for early migratory work ===================
str(GSI_body)
str(GSI_ED)
str(GSI_TE)


GSI_body <- GSI_body %>% mutate(Type = "Body Size", 
                                Estimate = Estimated_BodySize)
GSI_ED   <- GSI_ED %>% mutate(Type = "Energy Density", 
                              Estimate = Estimated_EnergyDensity)
GSI_TE   <- GSI_TE %>% mutate(Type = "Total Energy", 
                              Estimate = Estimated_TotalEnergy)
GSI_all <- bind_rows(GSI_body, GSI_ED, GSI_TE)
GSI_all <- GSI_all %>%
  mutate(IsChitina = ifelse(GSI == "Chitina", "Chitina", "Other"))

# Data excluding Chitina for regression fits
GSI_noChitina <- GSI_all %>% filter(GSI != "Chitina")

facet_colors <- c(
  "Body Size" = "#E69F00",      # orange
  "Energy Density" = "#56B4E9", # blue
  "Total Energy" = "#009E73"    # green
)

colors_GSI <- c(
  "Bremner" = "#E0B300",   
  "Chitina" = "black",  #"#FFE5CCFF"
  "Gulkana" = "#A50021FF",   
  "GulkanaHatchery" = "#D82632FF", 
  "Tazlina" = "#FF5C5C",   # reddish
  "Slana" = "#CC5800FF",
  "KlutinaLake" = "#FF8E32FF", 
  "KlutinaTonsinaOutlet" = "#E56B00", 
  "TanadaCopperLakes" = "#993F00FF")

work.condition <- ggplot() +
  # Regression lines manually colored by facet
  geom_smooth(
    data = GSI_noChitina %>% filter(Type == "Body Size"),
    aes(x = Avg_Work, y = Estimate),
    method = "lm",
    se = TRUE,
    color = facet_colors["Body Size"],
    fill = "lightgrey",
    alpha = 0.4,
    linewidth = 1.5,
    inherit.aes = FALSE,
    show.legend = FALSE
  ) +
  geom_smooth(
    data = GSI_noChitina %>% filter(Type == "Energy Density"),
    aes(x = Avg_Work, y = Estimate),
    method = "lm",
    se = TRUE,
    color = facet_colors["Energy Density"],
    fill = "lightgrey",
    alpha = 0.4,
    linewidth = 1.5,
    inherit.aes = FALSE,
    show.legend = FALSE
  ) +
  geom_smooth(
    data = GSI_noChitina %>% filter(Type == "Total Energy"),
    aes(x = Avg_Work, y = Estimate),
    method = "lm",
    se = TRUE,
    color = facet_colors["Total Energy"],
    fill = "lightgrey",
    alpha = 0.4,
    linewidth = 1.5,
    inherit.aes = FALSE,
    show.legend = FALSE
  )  +
  # Points for all stocks except Chitina
  geom_point(
    data = GSI_all %>% filter(GSI != "Chitina"),
    aes(x = Avg_Work, y = Estimate, color = GSI),
    shape = 16,
    size = 10
  ) +
  # Chitina as X
  geom_point(
    data = GSI_all %>% filter(GSI == "Chitina"),
    aes(x = Avg_Work, y = Estimate, color = GSI),
    shape = 4,
    size = 10,
    stroke = 1.5
  ) +
  # Facet by trait
  facet_wrap(~Type, scales = "free_y") +
  # Stock colors for points (legend)
  scale_color_manual(values = colors_GSI) +
  # Labels and theme
  labs(
    x = "Migratory Work (km²)",
    y = "Average Weighted Parameter Estimate",
    color = "Genetic Stock"
  ) +
  theme_minimal() +
  theme(
    panel.spacing.x = unit(2, "lines"),
    panel.spacing = unit(1.5, "lines"),
    # Facet header styling
    strip.text = element_text(size = 30, face = "bold", color = "white"),
    strip.background = element_rect(fill = "black", color = "black"),
    # Axis title margins
    axis.title.x = element_text(size = 30, face = "bold", margin = margin(t = 15)),
    axis.title.y = element_text(size = 30, face = "bold", margin = margin(r = 15)),
    #legend edits
    legend.title = element_text(size =24, face = "bold"),
    legend.text = element_text(size =20),
    # Axis text
    axis.text = element_text(size = 24, color = "black"),
    # Panel border
    panel.border = element_rect(color = "black", fill = NA, linewidth = 1),
    # Grid tweaks
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(color = "grey90")
  )






#================ Add regression stats to plots ===================
library(dplyr)
library(broom)

# Fit linear models by Type (facet) excluding Chitina
regression_stats <- GSI_noChitina %>%
  group_by(Type) %>%
  do({
    model <- lm(Estimate ~ Avg_Work, data = .)
    glance_model <- broom::glance(model)
    data.frame(
      R2 = glance_model$r.squared,
      p_value = glance_model$p.value
    )
  }) %>%
  ungroup()

# Compute top-left coordinates per facet
# Use min x and max y within each facet (Type)
coords <- GSI_noChitina %>%
  group_by(Type) %>%
  summarise(
    x = min(Avg_Work, na.rm = TRUE),
    y = max(Estimate, na.rm = TRUE)
  )

# Combine with regression stats
regression_stats <- regression_stats %>%
  left_join(coords, by = "Type")

#### Add A, B, C labels to each panel
# Create a small data frame of facet labels
facet_labels <- data.frame(
  Type = c("Body Size", "Energy Density", "Total Energy"),  # must match your facet variable names exactly
  label = c("a", "b", "c"),
  x = Inf,
  y = -Inf
)

# Add to plot
GSI.work.condition <- work.condition +
  geom_text(
    data = regression_stats,
    aes(
      x = x, 
      y = y, 
      label = paste0("R² = ", round(R2, 2), "\n", "p = ", signif(p_value, 2))
    ),
    inherit.aes = FALSE,
    hjust = 0, vjust = 0.5,   # top-left
    size = 8
  ) +
  geom_text(
    data = facet_labels,
    aes(x = x, y = y, label = label),
    hjust = 2, vjust = -1,     # push inward from the edges
    size = 12, fontface = "bold",  # adjust size/style
    inherit.aes = FALSE
  )


ggsave(
  filename = "AICFigures/Work_GSI_Condition_RegressionPlot.jpeg",    # output file name
  plot = GSI.work.condition,              # the ggplot object
  width = 22,                     # width in inches
  height = 12,                    # height in inches
  dpi = 300                        # resolution (higher = better quality)
)
```



### GSI Early Migratory Work vs fecundity Figure
```{r}
library(dplyr)
library(ggplot2)

rm(list = ls())

#Download Work Data set
WorkData <- read.csv("lowerriver_GSI_PCscores.csv")[-1]
str(WorkData)
WorkData$Group_Assignment <- as.factor(WorkData$Group_Assignment)
levels(WorkData$Group_Assignment) #levels are not all consistent. Need to fix this

# Strip whitespace
WorkData$Group_Assignment <- trimws(WorkData$Group_Assignment)

# Standardize levels
WorkData$Group_Assignment <- factor(WorkData$Group_Assignment)
levels(WorkData$Group_Assignment)

# Clean up levels manually
levels(WorkData$Group_Assignment)[levels(WorkData$Group_Assignment) == "Gulkana "] <- "Gulkana"
levels(WorkData$Group_Assignment)[levels(WorkData$Group_Assignment) == "Gulkanahatchery"] <- "GulkanaHatchery"
levels(WorkData$Group_Assignment)[levels(WorkData$Group_Assignment) == "KlutinaTonsinaOutlets"] <- "KlutinaTonsinaOutlet"
levels(WorkData$Group_Assignment)[levels(WorkData$Group_Assignment) == "insufficient genotypes"] <- "insufficient_genotypes"

# Then drop the insufficient genotypes
WorkData <- subset(WorkData, Group_Assignment != "insufficient_genotypes")
WorkData <- subset(WorkData, Group_Assignment != "LowerGroups")
WorkData$Group_Assignment <- droplevels(WorkData$Group_Assignment)



#download coefficient datasets for body size, energy density, total energy
fecundity <- read.csv("fecundity_GSI/fecundity_GSI_ModelAvg_Coefs_withLikelihoods.csv", row.names = 1)



#================ fecundity estimate calculations according to intercept =============
# Step 1: Extract intercept
str(fecundity)
intercept_fecundity <- fecundity["(Intercept)", "Avg_Coef"]

# Step 2: Extract Group_Assignment effects
GSI_fecundity <- fecundity[grep("^Group_Assignment", rownames(fecundity)), ]
GSI_fecundity <- GSI_fecundity[!grepl(":", rownames(GSI_fecundity)), ]  # remove interaction terms

# Extract location names (remove "Collection_Location" from row names)
GSI_fecundity$GSI <- gsub("Group_Assignment", "", rownames(GSI_fecundity))

# Step 3: Add intercept to each to get estimated fecundity
GSI_fecundity$Estimated_Fecundity <- intercept_fecundity + GSI_fecundity$Avg_Coef

# Step 4: Add back the reference location (intercept only)
ref_location <- levels(WorkData$Group_Assignment)[1]  # Assumes first level is the reference
ref_row <- data.frame(
  Avg_Coef = intercept_fecundity,
  CI_Lower = fecundity["(Intercept)", "CI_Lower"],
  CI_Upper = fecundity["(Intercept)", "CI_Upper"],
  SE = fecundity["(Intercept)", "SE"],
  ParamLikelihood = fecundity["(Intercept)", "ParamLikelihood"],
  GSI = ref_location,
  Estimated_Fecundity = intercept_fecundity
)

# Step 5: Combine
GSI_fecundity <- rbind(ref_row, GSI_fecundity)
rownames(GSI_fecundity) <- NULL
GSI_fecundity <- GSI_fecundity[, c("GSI", setdiff(names(GSI_fecundity), "GSI"))]

# Step 6: Compute average Work per location
library(dplyr)

# Check unique values
unique(WorkData$Group_Assignment)
avg_work_fecundity <- WorkData %>%
  dplyr::group_by(Group_Assignment) %>%
  dplyr::summarise(Avg_Work = mean(Work_km2, na.rm = TRUE), .groups = "drop")

# Step 7: Merge with estimates
GSI_fecundity <- merge(GSI_fecundity, avg_work_fecundity, by.x = "GSI", by.y = "Group_Assignment") 
str(GSI_fecundity) #final fecundity dataframe for work regressions




#================== Now, make figures of regressions for early migratory work ===================
str(GSI_fecundity)
GSI_fecundity$GSI <- factor(GSI_fecundity$GSI,
                 levels = c("Bremner",
                            "Chitina",
                            "KlutinaTonsinaOutlet",
                            "KlutinaLake",
                            "Tazlina",
                            "Slana",
                            "Gulkana",
                            "TanadaCopperLakes",
                            "GulkanaHatchery"))

# Data excluding Chitina for regression fits
GSI_noChitina <- GSI_fecundity %>% filter(GSI != "Chitina")

#fecundity color is = "#0072B2"

colors_GSI <- c(
  "Bremner" = "#E0B300",   
  "Chitina" = "black",  #"#FFE5CCFF"
  "Gulkana" = "#A50021FF",   
  "GulkanaHatchery" = "#D82632FF", 
  "Tazlina" = "#FF5C5C",   # reddish
  "Slana" = "#CC5800FF",
  "KlutinaLake" = "#FF8E32FF", 
  "KlutinaTonsinaOutlet" = "#E56B00", 
  "TanadaCopperLakes" = "#993F00FF")

GSI_fecundity$Facet <- "Fecundity"

work.fecundity <- ggplot() +
  # Regression lines manually colored by facet
  geom_smooth(
    data = GSI_noChitina,
    aes(x = Avg_Work, y = Estimated_Fecundity),
    method = "lm",
    se = TRUE,
    color = "#0072B2",
    fill = "lightgrey",
    alpha = 0.4,
    linewidth = 1.5,
    inherit.aes = FALSE,
    show.legend = FALSE
  ) +
  # Points for all stocks except Chitina
  geom_point(
    data = GSI_fecundity %>% filter(GSI != "Chitina"),
    aes(x = Avg_Work, y = Estimated_Fecundity, color = GSI),
    shape = 16,
    size = 10
  ) +
  # Chitina as X
  geom_point(
    data = GSI_fecundity %>% filter(GSI == "Chitina"),
    aes(x = Avg_Work, y = Estimated_Fecundity, color = GSI),
    shape = 4,
    size = 10,
    stroke = 1.5
  ) +
  scale_color_manual(values = colors_GSI) +
  # Labels and theme
  labs(
    x = "Migratory Work (km²)",
    y = "Average Weighted Parameter Estimate",
    color = "Genetic Stock"
  ) +
  facet_wrap(~Facet, strip.position = "top") +
  theme_minimal() +
  theme(
    panel.spacing.x = unit(2, "lines"),
    panel.spacing = unit(1.5, "lines"),
    # Facet header styling
    strip.text = element_text(size = 30, face = "bold", color = "white"),
    strip.background = element_rect(fill = "black", color = "black"),
    # Axis title margins
    axis.title.x = element_text(size = 30, face = "bold", margin = margin(t = 15)),
    axis.title.y = element_text(size = 30, face = "bold", margin = margin(r = 15)),
    #legend edits
    legend.title = element_text(size =24, face = "bold"),
    legend.text = element_text(size =20),
    # Axis text
    axis.text = element_text(size = 24, color = "black"),
    # Panel border
    panel.border = element_rect(color = "black", fill = NA, linewidth = 1),
    # Grid tweaks
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(color = "grey90")
  )






#================ Add regression stats to plots ===================
library(dplyr)
library(broom)

# Fit linear model excluding Chitina
fec_model <- lm(Estimated_Fecundity ~ Avg_Work, data = GSI_noChitina)


# 2. Extract R² and p-value
model_stats <- broom::glance(fec_model) %>%
  mutate(
    label = paste0("R² = ", round(r.squared, 3),
                   "\nP = ", signif(p.value, 3)),
    x = min(GSI_noChitina$Avg_Work),   # x position for label
    y = max(GSI_noChitina$Estimated_Fecundity) # y position for label
  )

# 3. Add the label to your plot
work.fecundity1 <- work.fecundity +
  geom_text(
    data = model_stats,
    aes(x = x, y = y, label = label),
    hjust = 0, vjust = -1,    # top-left corner
    size = 8
  )

work.fecundity1



ggsave(
  filename = "AICFigures/Work_GSI_Fecundity_RegressionPlot.jpeg",    # output file name
  plot = work.fecundity1,              # the ggplot object
  width = 18,                     # width in inches
  height = 12,                    # height in inches
  dpi = 300                        # resolution (higher = better quality)
)


```